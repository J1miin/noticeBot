import requests
from datetime import datetime
from bs4 import BeautifulSoup
import re

def crawl_notice(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    
    today = datetime.today().strftime('%Y.%m.%d.')
    y = datetime.today().strftime('%Y')
    m = datetime.today().strftime('%m')
    d = datetime.today().strftime('%d')
    # ê³µì§€ì‚¬í•­ ì œëª©, ë§í¬ ì¶”ì¶œ
    notices = []
    notices.append(f"ğŸ“ {y}ë…„ {m}ì›” {d}ì¼ ê³µì§€ì…ë‹ˆë‹¤.")

    for item in soup.select('li'):  # ê³µì§€ì‚¬í•­ í•­ëª©ì´ í¬í•¨ëœ li íƒœê·¸ ì„ íƒ
        if item.select_one('span.fix'):
            continue

        # ì œëª©ì´ í¬í•¨ëœ p.tit íƒœê·¸ ì„ íƒ
        title_tag = item.select_one('p.tit')
        if title_tag:
            title = title_tag.get_text(strip=True)  # ì œëª©ë§Œ ì¶”ì¶œ

            # ë§í¬ê°€ í¬í•¨ëœ a íƒœê·¸ ì„ íƒ
            link_tag = item.select_one('a[href]')
            if link_tag:
                onclick_value = link_tag.get('onclick', '')
                
                # goDetail() í•¨ìˆ˜ì—ì„œ ìˆ«ì ì¶”ì¶œ
                match = re.search(r'goDetail\((\d+)\)', onclick_value)
                if match:
                    detail_id = match.group(1)  # ìˆ«ì ì¶”ì¶œ
                    link = f"https://www.dongguk.edu/article/HAKSANOTICE/detail/{detail_id}"  # ë§í¬ ìƒì„±
                else:
                    link = 'ë§í¬ ì—†ìŒ'
            else:
                link = 'ë§í¬ ì—†ìŒ'
            
            # ë‚ ì§œ ì •ë³´ê°€ ë‹´ê¸´ .info í´ë˜ìŠ¤ê°€ ìˆëŠ” div íƒœê·¸ ì°¾ê¸°
            info_tag = item.select_one('.info')
            if info_tag:
                date_str = info_tag.select_one('span').get_text(strip=True)
                
                try:
                    notice_date = datetime.strptime(date_str, '%Y.%m.%d.').strftime('%Y.%m.%d.')
                except ValueError:
                    continue  # ë‚ ì§œ í˜•ì‹ì´ ë§ì§€ ì•Šìœ¼ë©´ ê±´ë„ˆëœ€

                # ì˜¤ëŠ˜ ë‚ ì§œì˜ ê³µì§€ì‚¬í•­ë§Œ ì¶”ê°€
                if notice_date == today:
                    notices.append(f"{title}\n{link}")
    
    # ì˜¤ëŠ˜ ë‚ ì§œì— ì˜¬ë¼ì˜¨ ê³µì§€ê°€ ì—†ìœ¼ë©´ ì•ˆë‚´ ë¬¸êµ¬ ì¶”ê°€
    if len(notices) == 1:  # ì²« ë²ˆì§¸ í•­ëª©ì€ "ì˜¤ëŠ˜ ê³µì§€ì…ë‹ˆë‹¤."ë¼ì„œ, ê·¸ ì´í›„ì— ê³µì§€ì‚¬í•­ì´ ì—†ìœ¼ë©´
        notices.append("ì˜¤ëŠ˜ ì˜¬ë¼ì˜¨ ê³µì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ê³µì§€ì‚¬í•­ì„ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜ (ë””ìŠ¤ì½”ë“œ ë´‡ì—ì„œ ì‚¬ìš© ê°€ëŠ¥)
    return "\n\n".join(notices)


if __name__ == "__main__":
    today = crawl_notice()
    notices = crawl_notice()
    print(notices)  # ì¶”ì¶œëœ ê³µì§€ì‚¬í•­ì„ ì¶œë ¥
